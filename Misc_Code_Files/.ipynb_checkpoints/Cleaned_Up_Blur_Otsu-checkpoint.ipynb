{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "    - When Choosing the Block size it may be helpful to also see with OTSU how the scales are layed out: the dense\n",
    "    - Could machine learning be could in choosing the best block size?\n",
    "    - How does Otsu as the method compare for finding the correct counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.dpi'] = 120\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labeled_imgs = []\n",
    "original_img = []\n",
    "original_img1 = []\n",
    "filter_img = []\n",
    "image_names = []\n",
    "\n",
    "num_scales_and_average_size = []\n",
    "sizes_of_scales = []\n",
    "total_stats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert(img):\n",
    "    return cv2.bitwise_not(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL TEST BINARIZATION\n",
      "\n",
      "THRESHOLDING WITH OTSU INITIALLY\n"
     ]
    }
   ],
   "source": [
    "#access img directory\n",
    "dirname = 'Anolis_cristatellus_images/'\n",
    "\n",
    "\n",
    "#create an iterator object for img directory\n",
    "directory = os.scandir(dirname)\n",
    "\n",
    "#for areas that are unfirform calculate the scale si\n",
    "\n",
    "#print(os.listdir(dirname))\n",
    "def threshold(customized):\n",
    "    index = 0;\n",
    "    images.clear\n",
    "    \n",
    "    if(len(customized) == 0):\n",
    "        print(\"THRESHOLDING WITH OTSU INITIALLY\")\n",
    "    #iterates through each image in the directory\n",
    "    for img in directory:\n",
    "        img_name = img.name\n",
    "        if (img_name != '.ipynb_checkpoints'):\n",
    "\n",
    "            if(len(customized) == 0):\n",
    "                image_names.append(img.name)\n",
    "            \n",
    "            #read the image, convert to grayscale add to array and title + blur\n",
    "            img = cv2.imread(dirname + img_name)\n",
    "            original_img1.append(img)\n",
    "            #img = invert(img)\n",
    "            \n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            original_img.append(gray)\n",
    "            title = img_name\n",
    "            img = gray\n",
    "            \n",
    "            if(len(customized) > 0 and block_size[index][0] > 15):\n",
    "                blur = cv2.GaussianBlur(img,(5,5),1)\n",
    "                blur = cv2.bilateralFilter(blur,10,10,100)\n",
    "            else:\n",
    "                blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "                \n",
    "           \n",
    "            filter_img.append(blur)\n",
    "            \n",
    "            #if the customized block size has not yet been determined this if statement will run\n",
    "            if(len(customized)==0):\n",
    "                #print(\"Initial Value used\")\n",
    "                ret, thresh = cv2.threshold(blur,0 , 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "                \n",
    "            #if customized block size has been determined\n",
    "            else:\n",
    "                thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, block_size[index][0], -2)\n",
    "                \n",
    "            kernel = np.ones((3,3),np.uint8)\n",
    "            \n",
    "            #if the customized iteration number has not yet been determined this if statement will run\n",
    "            if(len(customized)==0):\n",
    "                opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 4)\n",
    "            \n",
    "            #if customized array is greater than size 0 iteration number has been determined\n",
    "            else:\n",
    "                opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations=block_size[index][1])\n",
    "\n",
    "            \n",
    "            # sure background area\n",
    "            sure_bg = cv2.dilate(opening,kernel,iterations=1)\n",
    "\n",
    "            # Finding sure foreground area: What does cv2.DIST do?\n",
    "            dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "            ret, sure_fg = cv2.threshold(dist_transform, 1.5, 255, 0) \n",
    "\n",
    "            # Finding unknown region\n",
    "            sure_fg = np.uint8(sure_fg)\n",
    "            unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "            \n",
    "            #adding sure_fg binarization to list of images\n",
    "            images.append(sure_fg)\n",
    "            \n",
    "            \n",
    "            #plt.subplot(1,3,1), plt.imshow(gray, 'gray')\n",
    "            #plt.subplot(1,3,2), plt.imshow(sure_fg, 'gray') \n",
    "            #plt.show()\n",
    "        \n",
    "            # Label and count (taken from maggie's code)\n",
    "            # source: https://medium.com/analytics-vidhya/images-processing-segmentation-and-objects-counting-in-an-image-with-python-and-opencv-216cd38aca8e\n",
    "            count, labels = cv2.connectedComponents(sure_fg)                \n",
    "            count = count - 1 # background doesn't count as a scale\n",
    "            label_hue = np.uint8(179 * labels / np.max(labels))\n",
    "            blank_ch = 255 * np.ones_like(label_hue)\n",
    "            labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "            labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "            labeled_img[label_hue == 0] = 0\n",
    "            \n",
    "            if(len(customized) != 0):\n",
    "                labeled_imgs.append(labeled_img)\n",
    "            index += 1\n",
    "            \n",
    "print(\"INITIAL TEST BINARIZATION\\n\")\n",
    "threshold([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "print(len(images))\n",
    "#iterates through images to determine average size and count of scales in␣initial binarization\n",
    "for i in np.arange(len(images)):    \n",
    "    img = images[i]\n",
    "\n",
    "    binary_map = (img > 0).astype(np.uint8)\n",
    "    connectivity = 4 # or whatever you prefer\n",
    "    output = cv2.connectedComponentsWithStats(binary_map, connectivity, cv2.CV_32S)\n",
    "    num_labels = output[0]\n",
    "    \n",
    "    # The second cell is the label matrix\n",
    "    labels = output[1]\n",
    "    # The third cell is the stat matrix\n",
    "    stats = output[2]\n",
    "    # The fourth cell is the centroid matrix\n",
    "    centroids = output[3]\n",
    "    #print(centroids.shape)\n",
    "    \n",
    "\n",
    "    sizes_of_scales.append((stats[1:,-1]))\n",
    "    num_scales_and_average_size.append(([num_labels, np.average(stats[1:,-1])]))\n",
    "    total_stats.append([num_labels, stats[1:,-1], stats[1:,-1]])\n",
    "    \n",
    "print(len(num_scales_and_average_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "0\n",
      "BS 55\n",
      "Im 55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>size</th> <th>img_name</th> <th>block_size</th> <th>iterations</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>[ 9.    98.125]              </td> <td>212019Ventral-NoFlash-3.png</td> <td>65        </td> <td>2         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 1. nan]                    </td> <td>212019Dorsal-NoFlash-2.png </td> <td>15        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[   4.         2158.66666667]</td> <td>251165Ventral-NoFlash-2.png</td> <td>85        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[   7.  1437.5]              </td> <td>251165Ventral-Flash-3.png  </td> <td>85        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 2. 16.]                    </td> <td>212018Dorsal-NoFlash-3.png </td> <td>15        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 1. nan]                    </td> <td>212018Dorsal-NoFlash-2.png </td> <td>15        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 1. nan]                    </td> <td>214993Dorsal-NoFlash-1.png </td> <td>15        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[   7.         1335.66666667]</td> <td>251165Ventral-Flash-2.png  </td> <td>85        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[  8.         612.85714286]  </td> <td>251165Ventral-NoFlash-3.png</td> <td>85        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 1. nan]                    </td> <td>212019Dorsal-NoFlash-3.png </td> <td>15        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[  8.         126.85714286]  </td> <td>212019Ventral-NoFlash-2.png</td> <td>65        </td> <td>2         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 1. nan]                    </td> <td>212019Dorsal-NoFlash-1.png </td> <td>15        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[   6.  1560.8]              </td> <td>251165Ventral-NoFlash-1.png</td> <td>85        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 1. nan]                    </td> <td>214993Dorsal-NoFlash-3.png </td> <td>15        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 2. 28.]                    </td> <td>212018Dorsal-NoFlash-1.png </td> <td>15        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 1. nan]                    </td> <td>214993Dorsal-NoFlash-2.png </td> <td>15        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 10. 665.]                  </td> <td>251165Ventral-Flash-1.png  </td> <td>85        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[  8.         104.57142857]  </td> <td>212019Ventral-NoFlash-1.png</td> <td>65        </td> <td>2         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 22.         186.42857143]  </td> <td>226121Dorsal-NoFlash-2.png </td> <td>65        </td> <td>2         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 17.     365.3125]          </td> <td>226123Dorsal-NoFlash-1.png </td> <td>65        </td> <td>3         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 19.         185.94444444]  </td> <td>226121Dorsal-NoFlash-3.png </td> <td>65        </td> <td>2         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 19.         197.66666667]  </td> <td>226121Dorsal-NoFlash-1.png </td> <td>65        </td> <td>2         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 22.         187.85714286]  </td> <td>226123Dorsal-NoFlash-2.png </td> <td>65        </td> <td>2         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 18.         184.11764706]  </td> <td>226123Dorsal-NoFlash-3.png </td> <td>65        </td> <td>2         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 1. nan]                    </td> <td>214993Ventral-Flash-3.png  </td> <td>15        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 20.         110.73684211]  </td> <td>226123Dorsal-Flash-2.png   </td> <td>65        </td> <td>2         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[11.  85.7]                  </td> <td>212018Ventral-NoFlash-1.png</td> <td>65        </td> <td>2         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[15.         96.57142857]    </td> <td>226123Dorsal-Flash-3.png   </td> <td>65        </td> <td>2         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 11.  232.3]                </td> <td>251165Dorsal-NoFlash-1.png </td> <td>65        </td> <td>2         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 3. 91.]                    </td> <td>212020Ventral-NoFlash-1.png</td> <td>15        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 2. 96.]                    </td> <td>214993Ventral-Flash-2.png  </td> <td>15        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 5.  65.5]                  </td> <td>212020Ventral-NoFlash-3.png</td> <td>65        </td> <td>2         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 18.         246.88235294]  </td> <td>226123Dorsal-NoFlash-4.png </td> <td>65        </td> <td>2         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 14. 547.]                  </td> <td>251165Dorsal-NoFlash-3.png </td> <td>65        </td> <td>3         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 21.  192.2]                </td> <td>226123Dorsal-Flash-1.png   </td> <td>65        </td> <td>2         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[  7.  105.5]                </td> <td>212018Ventral-NoFlash-3.png</td> <td>65        </td> <td>2         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 8. 76.]                    </td> <td>212018Ventral-NoFlash-2.png</td> <td>65        </td> <td>2         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 18.         149.47058824]  </td> <td>251165Dorsal-NoFlash-2.png </td> <td>65        </td> <td>2         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[  4.         132.33333333]  </td> <td>212020Ventral-NoFlash-2.png</td> <td>65        </td> <td>2         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[  3.  179.5]                </td> <td>214993Ventral-Flash-1.png  </td> <td>15        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[  10.         1180.55555556]</td> <td>226123Ventral-Flash-3.png  </td> <td>85        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 1. nan]                    </td> <td>212020Dorsal-NoFlash-3.png </td> <td>15        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 1. nan]                    </td> <td>212020Dorsal-NoFlash-2.png </td> <td>15        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[  13.  1181.5]              </td> <td>226123Ventral-Flash-2.png  </td> <td>85        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 1. nan]                    </td> <td>212020Dorsal-NoFlash-1.png </td> <td>15        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[   8.         1386.85714286]</td> <td>226123Ventral-Flash-1.png  </td> <td>85        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[  9. 690.]                  </td> <td>226121Ventral-NoFlash-3.png</td> <td>85        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 3.  77.5]                  </td> <td>212010Ventral-NoFlash-2.png</td> <td>15        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[  4. 395.]                  </td> <td>212010Ventral-NoFlash-3.png</td> <td>65        </td> <td>3         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[   8.         1474.28571429]</td> <td>226121Ventral-NoFlash-2.png</td> <td>85        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 5.   75.75]                </td> <td>212010Ventral-NoFlash-1.png</td> <td>65        </td> <td>2         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[  6.  373.2]                </td> <td>226121Ventral-NoFlash-1.png</td> <td>65        </td> <td>3         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[   8.         1800.42857143]</td> <td>214993Ventral-NoFlash-1.png</td> <td>85        </td> <td>1         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[ 10.         176.22222222]  </td> <td>214993Ventral-NoFlash-3.png</td> <td>65        </td> <td>2         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>[   7.  1945.5]              </td> <td>214993Ventral-NoFlash-2.png</td> <td>85        </td> <td>1         </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "block_size = []\n",
    "\n",
    "#we need a better way of doing this: what's considerd shade and whats considerd not shade: usually big chunks of black\n",
    "#or white indicate a gradient: the issue is when the chunks are black: considerd background? \n",
    "#use uniformity somehow to fix this?\n",
    "index = 0\n",
    "\n",
    "print(len(num_scales_and_average_size))\n",
    "print(len(block_size))\n",
    "\n",
    "\n",
    "for stat in num_scales_and_average_size:\n",
    "    if stat[0] <= 3:\n",
    "        block_size.append([15,1])\n",
    "    elif stat[1] < 350:\n",
    "        block_size.append([65, 2])\n",
    "    elif stat[1] < 550:\n",
    "        block_size.append([65, 3])\n",
    "    else:\n",
    "        block_size.append([85, 1])\n",
    "    index +=1\n",
    "        \n",
    "print(\"BS\", len(block_size))\n",
    "print(\"Im\", len(images))\n",
    "size_and_iter = Table().with_columns(\"size\", num_scales_and_average_size, \"img_name\", image_names, \"block_size\", [i[0]for i in block_size], \"iterations\" ,[i[1] for i in block_size])\n",
    "size_and_iter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dirname = 'Anolis_cristatellus_images/'\n",
    "#create an iterator object for img directory\n",
    "directory = os.scandir(dirname)\n",
    "images = []\n",
    "\n",
    "threshold(block_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scale_counts = [i[0] for i in total_stats]\n",
    "all_sizes = [i[1] for i in total_stats]\n",
    "#sorts all_sizes so that the sizes of the scales are arranged from largest to␣smallest in array\n",
    "for array_index in np.arange(len(all_sizes) - 1):\n",
    "    all_sizes[array_index].sort()\n",
    "    all_sizes[array_index] = all_sizes[array_index][::-1]\n",
    "    averages = []\n",
    "for size_array in all_sizes:\n",
    "    num_nums = (np.rint(len(size_array)/2)).astype(int)\n",
    "    averages = np.append(averages, np.average(size_array[0:num_nums]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay(bw_img, color_mask, w1=0.2, w2=0.95):\n",
    "    a = cv2.cvtColor(bw_img, cv2.COLOR_GRAY2RGB)\n",
    "    a -= np.min(a)\n",
    "    a = a/np.max(a)*255\n",
    "    a = np.clip(a, a_min=0, a_max=255).astype(int)\n",
    "    b = np.clip(color_mask, a_min=0, a_max=255).astype(int)\n",
    "    c = cv2.addWeighted(b,w1,a,w2,0)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "without_r = []\n",
    "print(\"TRYING TO CLEAN UP THE IMAGES AND REMOVE SMALL SPECKELS: SHOULD TAKE INTO ACCOUNT DISTANCE AND SIZE\")\n",
    "\n",
    "index = 0;\n",
    "for img in images:\n",
    "    binary_map = (img > 0).astype(np.uint8)\n",
    "    connectivity = 4 # or whatever you prefer\n",
    "    output = cv2.connectedComponentsWithStats(binary_map, connectivity, cv2.CV_32S)\n",
    "    stats = output[2]\n",
    "\n",
    "\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    #opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    #closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel, iterations = 1)\n",
    "\n",
    "    \n",
    "    #review: what exactly does this do?\n",
    "    cnts = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for c in cnts:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area < (averages[index]/10):\n",
    "            img = cv2.drawContours(img, [c], -1, (0,0,0), -1)\n",
    "    \n",
    "    print(block_size[index][0])\n",
    "    plt.subplot(1,6,1), plt.imshow(original_img[index], 'gray')\n",
    "    plt.title(\"Org. Grayscale\", fontsize=5)\n",
    "    plt.subplot(1,6,2), plt.imshow(filter_img[index], 'gray')\n",
    "    plt.title(\"Filtered\", fontsize=5)\n",
    "    plt.subplot(1,6,3), plt.imshow(labeled_imgs[index], 'gray')\n",
    "    plt.title(\"Orig. Labeled\", fontsize=5)\n",
    "    plt.subplot(1,6,4), plt.imshow(img, 'gray')\n",
    "    plt.title(\"Noise Removed\", fontsize=5)\n",
    "\n",
    "\n",
    "    # Label and count (taken from maggie's code)\n",
    "    # source: https://medium.com/analytics-vidhya/images-processing-segmentation-and-objects-counting-in-an-image-with-python-and-opencv-216cd38aca8e\n",
    "    count, labels = cv2.connectedComponents(img)                \n",
    "    count = count - 1 # background doesn't count as a scale\n",
    "    label_hue = np.uint8(179 * labels / np.max(labels))\n",
    "    blank_ch = 255 * np.ones_like(label_hue)\n",
    "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "    labeled_img[label_hue == 0] = 0\n",
    "    without_r.append(labeled_img)\n",
    "\n",
    "    plt.subplot(1, 6, 5), plt.imshow(labeled_img, 'gray')\n",
    "    plt.title(\"Noise Rmvd. Labled\", fontsize=5)\n",
    "    plt.subplot(1, 6, 6), plt.imshow(overlay(original_img[index], labeled_img))\n",
    "    plt.title(\"Overlay. Count: \" + str(count), fontsize=5)\n",
    "\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    index = index + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(names):\n",
    "    trials = []\n",
    "    for name in names:\n",
    "        trials.append(\"Trial \" + str(name[-5]))\n",
    "    return trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten(image_names):\n",
    "    short_image_names = []\n",
    "    for name in image_names:\n",
    "        short_image_names.append(str(name[0:-6]))\n",
    "    return short_image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_image_names = shorten(image_names)\n",
    "trial_num = Table().with_column(\"Img Name\", short_image_names).group(\"Img Name\").sort(\"Img Name\").column(\"count\")\n",
    "data = Table().with_columns(\"Img Name\", short_image_names, \"trial\", trial(image_names), \"Counts\", final_counts)\n",
    "data = data.sort(\"Img Name\")\n",
    "data = data.pivot(\"trial\", \"Img Name\", \"Counts\", sum).with_column(\"# Trials\", trial_num)\n",
    "data = data.with_column(\"Average\", (data.column(\"Trial 1\") + data.column(\"Trial 2\") + data.column(\"Trial 3\") + data.column(\"Trial 4\"))/(data.column(\"# Trials\")))\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = [10, 60, 13, 55, 14, 48, 14, 41, 14, 18, 15, 6, 21, 19, 7, 21, 5, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.with_columns(\"Hand Counted Average\", actual, \"% Dif\", abs(data.column(\"Average\")/actual))\n",
    "dif = abs(data.column(\"Average\")/actual)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(\"% Dif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile = \"scalesData.csv\"\n",
    "#print([data.column(i) for i in np.arange(data.num_columns)])\n",
    "\n",
    "c1 = data.column(0)\n",
    "c2 = data.column(1)\n",
    "c3 = data.column(2)\n",
    "c4 = data.column(3)\n",
    "c5 = data.column(4)\n",
    "c6 = data.column(5)\n",
    "c7 = data.column(6)\n",
    "\n",
    "np.savetxt(\"scalesData.csv\", np.column_stack((c1, c2, c3, c4, c5, c6, c7)), fmt=\"%s\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"scalesData.csv\", data.column(0).tolist())\n",
    "print(data.column(0).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "without_r = []\n",
    "#find a way to draw the contors to see what is detected\n",
    "#use a different thing????\n",
    "\n",
    "print(\"TRYING TO CLEAN UP THE IMAGES AND REMOVE SMALL SPECKELS: SHOULD TAKE INTO ACCOUNT DISTANCE AND SIZE\")\n",
    "\n",
    "index = 0;\n",
    "final_counts = []\n",
    "\n",
    "print(\"Images\", len(images))\n",
    "for img in images:\n",
    "    binary_map = (img > 0).astype(np.uint8)\n",
    "    connectivity = 4 # or whatever you prefer\n",
    "    output = cv2.connectedComponentsWithStats(binary_map, connectivity, cv2.CV_32S)\n",
    "    stats = output[2]\n",
    "\n",
    "\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    #opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    #closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel, iterations = 1)\n",
    "\n",
    "    \n",
    "    #review: what exactly does this do?\n",
    "    cnts = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    print(len(cnts))\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    \n",
    "    print(averages[index]/10)\n",
    "    \n",
    "    print(\"scales:\", len(cnts))\n",
    "    \n",
    "    \n",
    "    for c in cnts:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area < (averages[index]/10):\n",
    "            img = cv2.drawContours(img, [c], -1, (0,0,0), -1)\n",
    "    \n",
    "    print(image_names[index])\n",
    "    print(block_size[index][0])\n",
    "    print(np.sqrt(average_size[index]))\n",
    "    plt.subplot(1,6,1), plt.imshow(original_img[index], 'gray')\n",
    "    plt.title(\"Org. Grayscale\", fontsize=5)\n",
    "    plt.subplot(1,6,2), plt.imshow(filter_img[index], 'gray')\n",
    "    plt.title(\"Filtered\", fontsize=5)\n",
    "    plt.subplot(1,6,3), plt.imshow(labeled_imgs[index], 'gray')\n",
    "    plt.title(\"Orig. Labeled\", fontsize=5)\n",
    "    plt.subplot(1,6,4), plt.imshow(img, 'gray')\n",
    "    plt.title(\"Noise Removed\", fontsize=5)\n",
    "\n",
    "\n",
    "    # Label and count (taken from maggie's code)\n",
    "    # source: https://medium.com/analytics-vidhya/images-processing-segmentation-and-objects-counting-in-an-image-with-python-and-opencv-216cd38aca8e\n",
    "    count, labels = cv2.connectedComponents(img)                \n",
    "    count = count - 1 # background doesn't count as a scale\n",
    "    label_hue = np.uint8(179 * labels / np.max(labels))\n",
    "    blank_ch = 255 * np.ones_like(label_hue)\n",
    "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "    labeled_img[label_hue == 0] = 0\n",
    "    without_r.append(labeled_img)\n",
    "\n",
    "    plt.subplot(1, 6, 5), plt.imshow(labeled_img, 'gray')\n",
    "    plt.title(\"Noise Rmvd. Labled\", fontsize=5)\n",
    "    plt.subplot(1, 6, 6), plt.imshow(overlay(original_img[index], labeled_img))\n",
    "    \n",
    "    final_counts.append(count)\n",
    "    plt.title(\"Overlay. Count: \" + str(count), fontsize=5)\n",
    "    \n",
    "    \n",
    "\n",
    "    plt.show()\n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
