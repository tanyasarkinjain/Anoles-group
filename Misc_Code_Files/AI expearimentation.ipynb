{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://github.com/tensorflow/tensorflow/issues/33285 used because getting an error\n",
    "\n",
    "import requests\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    # Legacy Python that doesn't verify HTTPS certificates by default\n",
    "    pass\n",
    "else:\n",
    "    # Handle target environment that doesn't support HTTPS verification\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 2s 977us/step - loss: 0.2534 - accuracy: 0.9231\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1048 - accuracy: 0.9670\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0725 - accuracy: 0.9775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x106a9e910>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#want to scale/normalize data\n",
    "x_train = tf.keras.utils.normalize(x_train, axis = 1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis = 1)\n",
    "\n",
    "\n",
    "#two types of models\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#what does flatten do?\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "\n",
    "#output layer: probability distribution\n",
    "model.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax))\n",
    "\n",
    "#AI tries to minimize loss: look into optimizers (10 kera ways?) Binary in case of cats/dogs?\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x143852130>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0], cmap = plt.cm.binary)\n",
    "#plt.imshow(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 620us/step - loss: 0.1126 - accuracy: 0.9661\n",
      "0.11257341504096985 0.9660999774932861\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: num_reader.model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('num_reader.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('num_reader.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = new_model.predict([x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.argmax(predictions[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to load in an outside data set \n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"/Users/tanyajain/Downloads/kagglecatsanddogs_3367a/PetImages\"\n",
    "CATEGORIES = [\"Dog\", \"Cat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cat', '.DS_Store', 'Dog']\n",
      "24946\n"
     ]
    }
   ],
   "source": [
    "training_data = []\n",
    "IMG_SIZE = 100\n",
    "\n",
    "print(os.listdir(DATADIR))\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category) #gets into cats or dogs directory\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            #print(path)\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            \n",
    "            \n",
    "create_training_data()\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for sample in training_data[:10]:\n",
    "    print (sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    Y.append(label)\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
