{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(imgName, blockSize):   \n",
    "    img = cv2.imread(imgName)\n",
    "    \n",
    "    # convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # blur and adaptive thresholding\n",
    "    # source: https://docs.opencv.org/master/d7/d4d/tutorial_py_thresholding.html\n",
    "    blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "    thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, blockSize, -2)\n",
    "\n",
    "    # Remove noise by opening\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN,kernel, iterations=2)\n",
    "    \n",
    "    # Check if opening was too much\n",
    "    numWhitePixels = cv2.countNonZero(opening) # number of foreground pixels\n",
    "    totalPixels = img.size / 3 # not sure why it has to be divided by 3\n",
    "    if numWhitePixels / totalPixels < 0.3:\n",
    "        # if opening resulted in less than 30% foreground, decrease number of opening iterations\n",
    "        opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN,kernel, iterations=1)\n",
    "    \n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform, 1.5, 255, 0)\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "\n",
    "    # Label and count\n",
    "    # source: https://medium.com/analytics-vidhya/images-processing-segmentation-and-objects-counting-in-an-image-with-python-and-opencv-216cd38aca8e\n",
    "    output = cv2.connectedComponentsWithStats(sure_fg, 8, cv2.CV_32S)\n",
    "    labels = output[1]\n",
    "    count = output[0] - 1 # background doesn't count as a scale\n",
    "    label_hue = np.uint8(179 * labels / np.max(labels))\n",
    "    blank_ch = 255 * np.ones_like(label_hue)\n",
    "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "    labeled_img[label_hue == 0] = 0\n",
    "    \n",
    "    stats = output[2]\n",
    "    areas = []\n",
    "    ratios = []\n",
    "    for i in range(1, count + 1): # start at 1 instead of 0 because don't want to count background as a scale\n",
    "        scaleArea = stats[i, cv2.CC_STAT_AREA]\n",
    "        boxArea = stats[i, cv2.CC_STAT_WIDTH] * stats[i, cv2.CC_STAT_HEIGHT]\n",
    "        ratios.append(scaleArea / boxArea)\n",
    "    avgRoundness = sum(ratios) / len(ratios)\n",
    "    return (avgRoundness, count, labeled_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countScales(imgName, start_size):\n",
    "    maxRoundness = 0\n",
    "    sizes = [s for s in range(start_size, startsize + 50) if s % 2 != 0]\n",
    "    for blockSize in sizes: # blocksize must be odd number\n",
    "        roundness, count, labeled_img = threshold(imgName, blockSize)\n",
    "        if roundness > maxRoundness:\n",
    "            maxRoundness = roundness\n",
    "            bestCount = count\n",
    "            bestSize = blockSize\n",
    "            bestImage = labeled_img\n",
    "    displayFinal(imgName, bestImage, bestCount, bestSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayFinal(imgName, labeled_img, count, blockSize):\n",
    "    \n",
    "    img = cv2.imread(imgName)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    plt.subplot(1, 2, 1), plt.imshow(gray, 'gray')\n",
    "    plt.title(imgName[12:])\n",
    "    \n",
    "    plt.subplot(1, 2, 2), plt.imshow(labeled_img, 'gray')\n",
    "    plt.title('Count: ' + str(count) + ', Blocksize:' + str(blockSize))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countScales('More_images/235227Ventral-Flash-1.png', 25)\n",
    "countScales('More_images/235227Ventral-Flash-2.png', 25)\n",
    "\n",
    "countScales('More_images/235227Ventral-NoFlash-1.png', 25)\n",
    "countScales('More_images/235227Ventral-NoFlash-2.png', 25)\n",
    "\n",
    "countScales('More_images/135164_V-1.png', 75)\n",
    "countScales('More_images/135164_V-2.png', 75)\n",
    "countScales('More_images/135164_V-3png.png', 75)\n",
    "\n",
    "countScales('More_images/135164_D-1.png', 25)\n",
    "countScales('More_images/135164_D-2.png', 25)\n",
    "countScales('More_images/135164_D-3.png', 25)\n",
    "\n",
    "countScales('More_images/235237Dorsal-Flash-1.png', 15)\n",
    "countScales('More_images/235237Dorsal-Flash-2.png', 15)\n",
    "\n",
    "countScales('More_images/235233Dorsal-Flash-1.png', 15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
